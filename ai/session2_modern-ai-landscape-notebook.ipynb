{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1b2c3d4e5f6"
      },
      "source": [
        "# Modern AI Landscape - Practical Examples\n",
        "\n",
        "This notebook demonstrates the key concepts from Session 2 through **hands-on examples**:\n",
        "\n",
        "1. **Classical vs. Modern AI**: See the difference between predictive models and generative AI\n",
        "2. **Prompt Engineering**: Learn how to effectively interact with LLMs\n",
        "3. **RAG (Retrieval-Augmented Generation)**: Build a simple document Q&A system\n",
        "\n",
        "By the end, you'll understand how modern AI works in practice and how it differs from traditional machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2c3d4e5f6g7"
      },
      "source": [
        "---\n",
        "## Example 1: Classical AI vs. Modern AI\n",
        "\n",
        "Let's compare how classical AI and modern AI solve different types of problems using the **same dataset** - customer reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3d4e5f6g7h8"
      },
      "source": [
        "# Setup: Install required libraries\n",
        "!pip install -q scikit-learn openai pandas\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# Sample customer reviews dataset\n",
        "reviews = [\n",
        "    \"This product is amazing! Best purchase ever.\",\n",
        "    \"Terrible quality. Broke after one week.\",\n",
        "    \"Good value for money, works as expected.\",\n",
        "    \"Waste of money. Very disappointed.\",\n",
        "    \"Excellent customer service and fast shipping!\",\n",
        "    \"Poor design, hard to use.\",\n",
        "    \"Love it! Highly recommend to everyone.\",\n",
        "    \"Not worth the price. Low quality materials.\"\n",
        "]\n",
        "\n",
        "# Labels: 1 = Positive, 0 = Negative\n",
        "labels = [1, 0, 1, 0, 1, 0, 1, 0]\n",
        "\n",
        "df = pd.DataFrame({'review': reviews, 'sentiment': labels})\n",
        "print(\"Dataset:\")\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4e5f6g7h8i9"
      },
      "source": [
        "### Classical AI Approach: Sentiment Classification\n",
        "\n",
        "Traditional ML uses **structured features** (word frequencies) to classify text into predefined categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5f6g7h8i9j0"
      },
      "source": [
        "# CLASSICAL AI: Train a sentiment classifier\n",
        "\n",
        "# Step 1: Convert text to numerical features (TF-IDF)\n",
        "vectorizer = TfidfVectorizer(max_features=20)\n",
        "X = vectorizer.fit_transform(reviews)\n",
        "\n",
        "# Step 2: Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.25, random_state=42)\n",
        "\n",
        "# Step 3: Train logistic regression classifier\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Predict on new review\n",
        "new_review = [\"Fantastic product, exceeded expectations!\"]\n",
        "new_review_vec = vectorizer.transform(new_review)\n",
        "prediction = classifier.predict(new_review_vec)[0]\n",
        "\n",
        "print(f\"\\n--- CLASSICAL AI RESULT ---\")\n",
        "print(f\"Review: {new_review[0]}\")\n",
        "print(f\"Prediction: {'Positive' if prediction == 1 else 'Negative'}\")\n",
        "print(f\"\\nKey insight: Classical AI assigns to predefined categories (Positive/Negative).\")\n",
        "print(f\"It cannot explain WHY or generate new content.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6g7h8i9j0k1"
      },
      "source": [
        "### Modern AI Approach: Generative Understanding\n",
        "\n",
        "Modern AI (LLMs) can not only classify but also **explain reasoning** and **generate responses**.\n",
        "\n",
        "**Note**: You'll need an OpenAI API key. For this demo, we'll show the prompt structure. In practice, you'd call the API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7h8i9j0k1l2"
      },
      "source": [
        "# MODERN AI: Use LLM for sentiment analysis + explanation\n",
        "\n",
        "# Construct prompt for LLM\n",
        "new_review = \"Fantastic product, exceeded expectations!\"\n",
        "\n",
        "prompt = f\"\"\"Analyze the sentiment of this customer review and explain your reasoning.\n",
        "\n",
        "Review: \"{new_review}\"\n",
        "\n",
        "Provide:\n",
        "1. Sentiment (Positive/Negative/Neutral)\n",
        "2. Confidence score (0-100%)\n",
        "3. Key phrases that influenced your decision\n",
        "4. Suggested response to the customer\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- MODERN AI PROMPT ---\")\n",
        "print(prompt)\n",
        "print(\"\\n--- SIMULATED LLM RESPONSE ---\")\n",
        "print(\"\"\"\n",
        "1. Sentiment: Positive\n",
        "2. Confidence: 95%\n",
        "3. Key phrases:\n",
        "   - \"Fantastic\" - strong positive adjective\n",
        "   - \"exceeded expectations\" - indicates superior performance\n",
        "4. Suggested response:\n",
        "   \"Thank you for your wonderful feedback! We're thrilled the product \n",
        "   exceeded your expectations. We'd love to hear more about your experience!\"\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\nüîë KEY DIFFERENCE:\")\n",
        "print(\"Classical AI: Predicts category (Positive)\")\n",
        "print(\"Modern AI: Understands context, explains reasoning, generates personalized responses\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8i9j0k1l2m3"
      },
      "source": [
        "---\n",
        "## Example 2: Prompt Engineering Fundamentals\n",
        "\n",
        "The quality of LLM outputs depends heavily on **how you prompt them**. Let's see the difference between basic and advanced prompting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9j0k1l2m3n4"
      },
      "source": [
        "# Scenario: Generate a product description for an e-commerce site\n",
        "\n",
        "product_features = {\n",
        "    'name': 'UltraLight Camping Tent',\n",
        "    'features': ['2-person capacity', 'Weighs 3 lbs', 'Waterproof', 'Easy setup'],\n",
        "    'price': '$179.99'\n",
        "}\n",
        "\n",
        "# ‚ùå POOR PROMPT: Vague, no context\n",
        "poor_prompt = f\"Write about {product_features['name']}\"\n",
        "\n",
        "print(\"--- POOR PROMPT ---\")\n",
        "print(poor_prompt)\n",
        "print(\"\\nSimulated Output:\")\n",
        "print(\"The UltraLight Camping Tent is a tent. It's good for camping.\")\n",
        "print(\"\\n‚ö†Ô∏è Problem: Too generic, not persuasive, no structure.\\n\")\n",
        "\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# ‚úÖ GOOD PROMPT: Specific role, format, constraints, examples\n",
        "good_prompt = f\"\"\"You are a professional e-commerce copywriter specializing in outdoor gear.\n",
        "\n",
        "Task: Write a compelling product description.\n",
        "\n",
        "Product: {product_features['name']}\n",
        "Features: {', '.join(product_features['features'])}\n",
        "Price: {product_features['price']}\n",
        "\n",
        "Requirements:\n",
        "- Length: 100-150 words\n",
        "- Tone: Adventurous yet professional\n",
        "- Include benefits (not just features)\n",
        "- Use persuasive language\n",
        "- End with a call-to-action\n",
        "\n",
        "Format:\n",
        "[Engaging headline]\n",
        "[Body paragraph 1-2]\n",
        "[Call to action]\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- GOOD PROMPT ---\")\n",
        "print(good_prompt)\n",
        "print(\"\\nSimulated Output:\")\n",
        "print(\"\"\"\n",
        "**Adventure Awaits Without the Weight**\n",
        "\n",
        "Escape to the wilderness with the UltraLight Camping Tent, engineered for \n",
        "adventurers who refuse to compromise. At just 3 pounds, this 2-person tent \n",
        "disappears in your pack, letting you trek farther and explore deeper. \n",
        "Waterproof construction keeps you dry through mountain storms, while the \n",
        "intuitive setup gets you sheltered in minutes‚Äîmore time enjoying the sunset, \n",
        "less time wrestling with poles. Whether you're conquering a multi-day trail \n",
        "or weekend camping with friends, this tent delivers comfort without bulk.\n",
        "\n",
        "At $179.99, invest in gear that matches your ambition. Order now and get \n",
        "free shipping on your next adventure.\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\n‚úÖ Result: Specific, persuasive, follows structure, includes benefits!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0k1l2m3n4o5"
      },
      "source": [
        "### Prompt Engineering Best Practices\n",
        "\n",
        "**Key elements of effective prompts:**\n",
        "1. **Role**: Define who the AI should be (\"You are a...\")\n",
        "2. **Context**: Provide necessary background information\n",
        "3. **Task**: Be specific about what you want\n",
        "4. **Constraints**: Set length, tone, format requirements\n",
        "5. **Examples**: Show the AI what good output looks like (few-shot learning)\n",
        "6. **Output Format**: Specify structure (bullet points, JSON, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1l2m3n4o5p6"
      },
      "source": [
        "# Few-Shot Learning Example\n",
        "# Teaching the LLM by example rather than explicit rules\n",
        "\n",
        "few_shot_prompt = \"\"\"\n",
        "Extract key information from product reviews in JSON format.\n",
        "\n",
        "Example 1:\n",
        "Review: \"Battery life is amazing, lasts 3 days! But screen is too small.\"\n",
        "Output: {\"pros\": [\"Long battery life (3 days)\"], \"cons\": [\"Small screen\"], \"rating_estimate\": 4}\n",
        "\n",
        "Example 2:\n",
        "Review: \"Terrible quality. Broke after 1 week. Customer service was rude.\"\n",
        "Output: {\"pros\": [], \"cons\": [\"Poor quality\", \"Broke quickly\", \"Bad customer service\"], \"rating_estimate\": 1}\n",
        "\n",
        "Now extract from this review:\n",
        "Review: \"Great camera quality and fast charging. Wish it had more storage.\"\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- FEW-SHOT LEARNING PROMPT ---\")\n",
        "print(few_shot_prompt)\n",
        "print(\"\\nExpected Output:\")\n",
        "print('{\"pros\": [\"Great camera quality\", \"Fast charging\"], \"cons\": [\"Limited storage\"], \"rating_estimate\": 4}')\n",
        "print(\"\\nüí° The AI learns the pattern from examples without explicit programming!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2m3n4o5p6q7"
      },
      "source": [
        "---\n",
        "## Example 3: RAG (Retrieval-Augmented Generation) Simplified\n",
        "\n",
        "RAG combines **information retrieval** with **LLM generation** to answer questions about specific documents. This is how ChatGPT can answer questions about *your* company docs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3n4o5p6q7r8"
      },
      "source": [
        "# Simulate a simple RAG system for company policy documents\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Company knowledge base (simplified documents)\n",
        "documents = [\n",
        "    \"Our return policy allows customers to return items within 30 days of purchase for a full refund. Items must be in original packaging and unused.\",\n",
        "    \"Shipping is free for orders over $50. Standard shipping takes 3-5 business days. Express shipping is available for $15 and takes 1-2 days.\",\n",
        "    \"Customer support is available Monday-Friday 9am-6pm EST. You can reach us by email at support@company.com or call 1-800-SUPPORT.\",\n",
        "    \"We offer a 1-year warranty on all products. The warranty covers manufacturing defects but does not cover damage from misuse or accidents.\",\n",
        "    \"Account passwords must be reset every 90 days for security. Passwords must be at least 12 characters and include numbers and symbols.\"\n",
        "]\n",
        "\n",
        "print(\"üìö KNOWLEDGE BASE (5 documents)\")\n",
        "for i, doc in enumerate(documents, 1):\n",
        "    print(f\"{i}. {doc[:60]}...\")\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4o5p6q7r8s9"
      },
      "source": [
        "# STEP 1: Vectorize documents (create embeddings)\n",
        "vectorizer = TfidfVectorizer()\n",
        "doc_vectors = vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"STEP 1: Documents converted to vectors ‚úì\")\n",
        "print(f\"Vector dimensions: {doc_vectors.shape[1]}\\n\")\n",
        "\n",
        "# STEP 2: User asks a question\n",
        "user_question = \"How long do I have to return a product?\"\n",
        "print(f\"USER QUESTION: '{user_question}'\\n\")\n",
        "\n",
        "# STEP 3: Convert question to vector\n",
        "question_vector = vectorizer.transform([user_question])\n",
        "\n",
        "# STEP 4: Find most similar documents (retrieval)\n",
        "similarities = cosine_similarity(question_vector, doc_vectors)[0]\n",
        "most_relevant_idx = np.argmax(similarities)\n",
        "most_relevant_doc = documents[most_relevant_idx]\n",
        "\n",
        "print(\"STEP 2-4: Retrieved most relevant document:\")\n",
        "print(f\"Document #{most_relevant_idx + 1}:\")\n",
        "print(f\"'{most_relevant_doc}'\")\n",
        "print(f\"Relevance score: {similarities[most_relevant_idx]:.3f}\\n\")\n",
        "\n",
        "# STEP 5: Generate answer using LLM + retrieved context\n",
        "rag_prompt = f\"\"\"Based on the following context, answer the user's question.\n",
        "\n",
        "Context: {most_relevant_doc}\n",
        "\n",
        "Question: {user_question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "print(\"STEP 5: LLM generates answer using retrieved context:\")\n",
        "print(\"\\nPrompt sent to LLM:\")\n",
        "print(rag_prompt)\n",
        "print(\"\\nSimulated LLM Response:\")\n",
        "print(\"You have 30 days from the date of purchase to return items for a full refund. Please ensure items are in their original packaging and unused.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5p6q7r8s9t0"
      },
      "source": [
        "### How RAG Works (Visual Summary)\n",
        "\n",
        "```\n",
        "Traditional LLM:\n",
        "Question ‚Üí LLM ‚Üí Answer (may hallucinate if info not in training data)\n",
        "\n",
        "RAG System:\n",
        "Question ‚Üí Vector Search ‚Üí Retrieve Relevant Docs ‚Üí LLM + Context ‚Üí Accurate Answer\n",
        "```\n",
        "\n",
        "**Key Benefits:**\n",
        "- ‚úÖ Answers based on YOUR documents (not just training data)\n",
        "- ‚úÖ Reduces hallucinations (AI making up facts)\n",
        "- ‚úÖ Can cite sources (\"According to document X...\")\n",
        "- ‚úÖ Easily updateable (add new docs without retraining)\n",
        "\n",
        "**Real-World Applications:**\n",
        "- Customer support chatbots\n",
        "- Legal document analysis\n",
        "- Medical literature review\n",
        "- Internal company knowledge bases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6q7r8s9t0u1"
      },
      "source": [
        "---\n",
        "## Summary & Key Takeaways\n",
        "\n",
        "Through these three examples, you've learned:\n",
        "\n",
        "**1. Classical vs. Modern AI**\n",
        "- Classical AI: Predicts categories from structured data (fast, cheap, narrow)\n",
        "- Modern AI: Generates content, understands context, explains reasoning (flexible, powerful)\n",
        "- Use case matters: Choose the right tool for the job\n",
        "\n",
        "**2. Prompt Engineering**\n",
        "- Quality of output depends on quality of prompts\n",
        "- Key elements: Role, Context, Task, Constraints, Examples, Format\n",
        "- Few-shot learning: Teach by example rather than explicit rules\n",
        "\n",
        "**3. RAG (Retrieval-Augmented Generation)**\n",
        "- Combines document search with LLM generation\n",
        "- Grounds AI responses in your specific data\n",
        "- Essential for enterprise AI applications\n",
        "\n",
        "---\n",
        "\n",
        "### Next Steps\n",
        "- **Practice**: Try different prompting strategies with ChatGPT or Claude\n",
        "- **Explore**: Build your own RAG system with LangChain or LlamaIndex\n",
        "- **Experiment**: Compare costs and performance of different LLMs (GPT-4 vs GPT-3.5 vs Claude)\n",
        "\n",
        "### Resources\n",
        "- OpenAI Cookbook: https://cookbook.openai.com/\n",
        "- LangChain Documentation: https://python.langchain.com/\n",
        "- Prompt Engineering Guide: https://www.promptingguide.ai/"
      ]
    }
  ]
}
